{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":47916,"databundleVersionId":5086073,"sourceType":"competition"}],"dockerImageVersionId":30397,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Homework 2: Phoneme Classification**\n","metadata":{"id":"OYlaRwNu7ojq"}},{"cell_type":"markdown","source":"Objectives:\n* Solve a classification problem with deep neural networks (DNNs).\n* Understand recursive neural networks (RNNs).\n\nIf you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com","metadata":{"id":"A7DRC5V7_8A5"}},{"cell_type":"markdown","source":"# Some Utility Functions\n**Fixes random number generator seeds for reproducibility.**","metadata":{"id":"pADUiYODJE1O"}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport random\n\ndef same_seeds(seed):\n    random.seed(seed) \n    np.random.seed(seed)  \n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed) \n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True","metadata":{"id":"BsZKgBZQJjaE","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2025-07-01T15:06:49.621230Z","iopub.execute_input":"2025-07-01T15:06:49.622246Z","iopub.status.idle":"2025-07-01T15:06:49.627492Z","shell.execute_reply.started":"2025-07-01T15:06:49.622215Z","shell.execute_reply":"2025-07-01T15:06:49.626547Z"},"trusted":true},"outputs":[],"execution_count":70},{"cell_type":"markdown","source":"**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n\nA phoneme may span several frames and is dependent to past and future frames. \\\nHence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n\nFeel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)","metadata":{"id":"_L_4anls8Drv"}},{"cell_type":"code","source":"import os\nimport torch\nfrom tqdm import tqdm\n\ndef load_feat(path):\n    feat = torch.load(path)\n    return feat\n\ndef shift(x, n):\n    if n < 0:\n        left = x[0].repeat(-n, 1)\n        right = x[:n]\n    elif n > 0:\n        right = x[-1].repeat(n, 1)\n        left = x[n:]\n    else:\n        return x\n\n    return torch.cat((left, right), dim=0)\n\ndef concat_feat(x, concat_n):\n    assert concat_n % 2 == 1 # n must be odd\n    if concat_n < 2:\n        return x\n    seq_len, feature_dim = x.size(0), x.size(1)\n    x = x.repeat(1, concat_n) \n    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n    mid = (concat_n // 2)\n    for r_idx in range(1, mid+1):\n        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n\n    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n\ndef preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8):\n    class_num = 41 # NOTE: pre-computed, should not need change\n\n    if split == 'train' or split == 'val':\n        mode = 'train'\n    elif split == 'test':\n        mode = 'test'\n    else:\n        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n\n    label_dict = {}\n    if mode == 'train':\n        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n            line = line.strip('\\n').split(' ')\n            label_dict[line[0]] = [int(p) for p in line[1:]]\n        \n        # split training and validation data\n        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n        random.shuffle(usage_list)\n        train_len = int(len(usage_list) * train_ratio)\n        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n\n    elif mode == 'test':\n        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n\n    usage_list = [line.strip('\\n') for line in usage_list]\n    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n\n    max_len = 3000000\n    X = torch.empty(max_len, 39 * concat_nframes)\n    if mode == 'train':\n        y = torch.empty(max_len, dtype=torch.long)\n\n    idx = 0\n    for i, fname in tqdm(enumerate(usage_list)):\n        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n        cur_len = len(feat)\n        feat = concat_feat(feat, concat_nframes)\n        if mode == 'train':\n          label = torch.LongTensor(label_dict[fname])\n\n        X[idx: idx + cur_len, :] = feat\n        if mode == 'train':\n          y[idx: idx + cur_len] = label\n\n        idx += cur_len\n\n    X = X[:idx, :]\n    if mode == 'train':\n      y = y[:idx]\n\n    print(f'[INFO] {split} set')\n    print(X.shape)\n    if mode == 'train':\n      print(y.shape)\n      return X, y\n    else:\n      return X\n","metadata":{"id":"IJjLT8em-y9G","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2025-07-01T15:06:51.731365Z","iopub.execute_input":"2025-07-01T15:06:51.731969Z","iopub.status.idle":"2025-07-01T15:06:51.750345Z","shell.execute_reply.started":"2025-07-01T15:06:51.731938Z","shell.execute_reply":"2025-07-01T15:06:51.749401Z"},"trusted":true},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"us5XW_x6udZQ"}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass LibriDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.data = X\n        if y is not None:\n            self.label = torch.LongTensor(y)\n        else:\n            self.label = None\n\n    def __getitem__(self, idx):\n        if self.label is not None:\n            return self.data[idx], self.label[idx]\n        else:\n            return self.data[idx]\n\n    def __len__(self):\n        return len(self.data)\n","metadata":{"id":"Fjf5EcmJtf4e","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2025-07-01T15:06:54.510484Z","iopub.execute_input":"2025-07-01T15:06:54.511106Z","iopub.status.idle":"2025-07-01T15:06:54.517314Z","shell.execute_reply.started":"2025-07-01T15:06:54.511071Z","shell.execute_reply":"2025-07-01T15:06:54.516302Z"},"trusted":true},"outputs":[],"execution_count":72},{"cell_type":"markdown","source":"# Model\nFeel free to modify the structure of the model.","metadata":{"id":"IRqKNvNZwe3V"}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass BasicBlock(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(BasicBlock, self).__init__()\n\n        self.block = nn.Sequential(\n            nn.LeakyReLU(),\n          nn.BatchNorm1d(2 * hidden_dim),\n          nn.Dropout(0.5),\n          nn.Linear(2 * hidden_dim, hidden_dim),\n          nn.LeakyReLU(),\n          nn.BatchNorm1d(hidden_dim),\n          nn.Dropout(0.5),\n          nn.Linear(hidden_dim, 41)\n        )\n\n    def forward(self, x):\n        x = self.block(x)\n        return x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n        super(Classifier, self).__init__()\n\n        self.fc = nn.Sequential(\n            BasicBlock(input_dim, hidden_dim),\n            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n            nn.Linear(hidden_dim, output_dim)\n        )\n\n    def forward(self, x):\n        x = self.fc(x)\n        return x","metadata":{"id":"Bg-GRd7ywdrL","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2025-07-01T15:06:58.134636Z","iopub.execute_input":"2025-07-01T15:06:58.134983Z","iopub.status.idle":"2025-07-01T15:06:58.143388Z","shell.execute_reply.started":"2025-07-01T15:06:58.134957Z","shell.execute_reply":"2025-07-01T15:06:58.142267Z"},"trusted":true},"outputs":[],"execution_count":73},{"cell_type":"markdown","source":"# Hyper-parameters","metadata":{"id":"TlIq8JeqvvHC"}},{"cell_type":"code","source":"# data prarameters\nconcat_nframes = 11            # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\ntrain_ratio = 0.8              # the ratio of data used for training, the rest will be used for validation\n\n# training parameters\nseed = 1213                        # random seed\nbatch_size = 128                # batch size\nnum_epoch = 50                  # the number of training epoch\nlearning_rate = 5e-3        # learning rate\nmodel_path = './model.ckpt'     # the path where the checkpoint will be saved\n\n# model parameters\ninput_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\nhidden_layers = 3               # the number of hidden layers\nhidden_dim = 512               # the hidden dim","metadata":{"id":"iIHn79Iav1ri","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2025-07-01T15:07:01.048536Z","iopub.execute_input":"2025-07-01T15:07:01.048917Z","iopub.status.idle":"2025-07-01T15:07:01.054385Z","shell.execute_reply.started":"2025-07-01T15:07:01.048886Z","shell.execute_reply":"2025-07-01T15:07:01.053335Z"},"trusted":true},"outputs":[],"execution_count":74},{"cell_type":"markdown","source":"# Dataloader","metadata":{"id":"IIUFRgG5yoDn"}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport gc\n\nsame_seeds(seed)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'DEVICE: {device}')\n\n# preprocess data\ntrain_X, train_y = preprocess_data(split='train', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\nval_X, val_y = preprocess_data(split='val', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n\n# get dataset\ntrain_set = LibriDataset(train_X, train_y)\nval_set = LibriDataset(val_X, val_y)\n\n# remove raw feature to save memory\ndel train_X, train_y, val_X, val_y\ngc.collect()\n\n# get dataloader\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)","metadata":{"id":"c1zI3v5jyrDn","outputId":"6e7eeb1b-b76a-4846-b9b4-055d66c05661","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2025-07-01T15:07:19.648425Z","iopub.execute_input":"2025-07-01T15:07:19.649119Z","iopub.status.idle":"2025-07-01T15:07:31.362487Z","shell.execute_reply.started":"2025-07-01T15:07:19.649086Z","shell.execute_reply":"2025-07-01T15:07:31.361618Z"},"trusted":true},"outputs":[{"name":"stdout","text":"DEVICE: cuda\n[Dataset] - # phone classes: 41, number of utterances for train: 2743\n","output_type":"stream"},{"name":"stderr","text":"2743it [00:08, 310.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"[INFO] train set\ntorch.Size([1694451, 429])\ntorch.Size([1694451])\n[Dataset] - # phone classes: 41, number of utterances for val: 686\n","output_type":"stream"},{"name":"stderr","text":"686it [00:01, 426.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"[INFO] val set\ntorch.Size([419994, 429])\ntorch.Size([419994])\n","output_type":"stream"}],"execution_count":76},{"cell_type":"markdown","source":"# Training","metadata":{"id":"pwWH1KIqzxEr"}},{"cell_type":"code","source":"create model, define a loss function, and optimizer\nmodel = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\ncriterion = nn.CrossEntropyLoss() \n# # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# best_acc = 0.0\nfor epoch in range(num_epoch):\n    train_acc = 0.0\n    train_loss = 0.0\n    val_acc = 0.0\n    val_loss = 0.0\n    \n    # training\n    model.train() # set the model to training mode\n    for i, batch in enumerate(tqdm(train_loader)):\n        features, labels = batch\n        features = features.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad() \n        outputs = model(features) \n        \n        loss = criterion(outputs, labels)\n        loss.backward() \n        optimizer.step() \n        \n        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n        train_loss += loss.item()\n    \n    # validation\n    model.eval() # set the model to evaluation mode\n    with torch.no_grad():\n        for i, batch in enumerate(tqdm(val_loader)):\n            features, labels = batch\n            features = features.to(device)\n            labels = labels.to(device)\n            outputs = model(features)\n            \n            loss = criterion(outputs, labels) \n            \n            _, val_pred = torch.max(outputs, 1) \n            val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n            val_loss += loss.item()\n\n    print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/len(train_set):3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/len(val_set):3.5f} loss: {val_loss/len(val_loader):3.5f}')\n\n    # if the model improves, save a checkpoint at this epoch\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), model_path)\n        print(f'saving model with acc {best_acc/len(val_set):.5f}')\n","metadata":{"id":"CdMWsBs7zzNs","outputId":"426e0a6c-02bd-4f59-e45c-b05e3f28965d","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2025-07-01T14:01:33.425263Z","iopub.execute_input":"2025-07-01T14:01:33.425624Z","iopub.status.idle":"2025-07-01T15:02:13.184275Z","shell.execute_reply.started":"2025-07-01T14:01:33.425593Z","shell.execute_reply":"2025-07-01T15:02:13.183292Z"},"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 200.73it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 550.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"[001/050] Train Acc: 0.85784 Loss: 0.40380 | Val Acc: 0.85274 loss: 0.51423\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 201.11it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 556.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"[002/050] Train Acc: 0.85832 Loss: 0.40366 | Val Acc: 0.85313 loss: 0.51653\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 200.84it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 550.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"[003/050] Train Acc: 0.85848 Loss: 0.40376 | Val Acc: 0.85314 loss: 0.51670\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 201.07it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 557.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"[004/050] Train Acc: 0.85824 Loss: 0.40385 | Val Acc: 0.85247 loss: 0.51754\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 199.85it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 565.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"[005/050] Train Acc: 0.85874 Loss: 0.40286 | Val Acc: 0.85423 loss: 0.51716\nsaving model with acc 0.85423\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 202.52it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 554.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"[006/050] Train Acc: 0.85825 Loss: 0.40370 | Val Acc: 0.85290 loss: 0.51967\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 202.05it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 540.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"[007/050] Train Acc: 0.85804 Loss: 0.40470 | Val Acc: 0.85365 loss: 0.51733\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 200.82it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 553.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"[008/050] Train Acc: 0.85800 Loss: 0.40429 | Val Acc: 0.85413 loss: 0.51453\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 201.51it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 550.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"[009/050] Train Acc: 0.85840 Loss: 0.40301 | Val Acc: 0.85385 loss: 0.51609\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 201.86it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 562.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"[010/050] Train Acc: 0.85849 Loss: 0.40325 | Val Acc: 0.85318 loss: 0.51665\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 201.84it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 549.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"[011/050] Train Acc: 0.85854 Loss: 0.40404 | Val Acc: 0.85342 loss: 0.51696\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 201.86it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 557.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"[012/050] Train Acc: 0.85850 Loss: 0.40286 | Val Acc: 0.85387 loss: 0.51870\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 203.29it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 552.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"[013/050] Train Acc: 0.85815 Loss: 0.40363 | Val Acc: 0.85337 loss: 0.51729\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 201.14it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 547.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"[014/050] Train Acc: 0.85815 Loss: 0.40380 | Val Acc: 0.85394 loss: 0.51632\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 202.75it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 552.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"[015/050] Train Acc: 0.85826 Loss: 0.40272 | Val Acc: 0.85411 loss: 0.51608\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 201.18it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 547.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"[016/050] Train Acc: 0.85820 Loss: 0.40321 | Val Acc: 0.85312 loss: 0.51520\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 202.01it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 557.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"[017/050] Train Acc: 0.85884 Loss: 0.40347 | Val Acc: 0.85346 loss: 0.51537\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 202.82it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 556.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"[018/050] Train Acc: 0.85871 Loss: 0.40351 | Val Acc: 0.85329 loss: 0.51660\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:05<00:00, 202.51it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 564.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[019/050] Train Acc: 0.85857 Loss: 0.40296 | Val Acc: 0.85414 loss: 0.51548\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:04<00:00, 204.28it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 560.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[020/050] Train Acc: 0.85805 Loss: 0.40427 | Val Acc: 0.85408 loss: 0.51605\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 199.63it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 556.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[021/050] Train Acc: 0.85814 Loss: 0.40333 | Val Acc: 0.85354 loss: 0.52023\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 198.77it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 506.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"[022/050] Train Acc: 0.85849 Loss: 0.40297 | Val Acc: 0.85355 loss: 0.51914\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:11<00:00, 185.33it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 508.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"[023/050] Train Acc: 0.85839 Loss: 0.40336 | Val Acc: 0.85286 loss: 0.51836\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:11<00:00, 184.17it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 509.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"[024/050] Train Acc: 0.85851 Loss: 0.40278 | Val Acc: 0.85285 loss: 0.51835\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:10<00:00, 187.82it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 511.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"[025/050] Train Acc: 0.85861 Loss: 0.40233 | Val Acc: 0.85357 loss: 0.52034\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:10<00:00, 188.32it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 510.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"[026/050] Train Acc: 0.85809 Loss: 0.40374 | Val Acc: 0.85387 loss: 0.51696\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:09<00:00, 189.76it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 533.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"[027/050] Train Acc: 0.85849 Loss: 0.40273 | Val Acc: 0.85246 loss: 0.51887\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:07<00:00, 195.52it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 536.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"[028/050] Train Acc: 0.85845 Loss: 0.40300 | Val Acc: 0.85352 loss: 0.51585\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:07<00:00, 195.67it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 535.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"[029/050] Train Acc: 0.85821 Loss: 0.40375 | Val Acc: 0.85381 loss: 0.51925\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:07<00:00, 195.67it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 535.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"[030/050] Train Acc: 0.85854 Loss: 0.40302 | Val Acc: 0.85336 loss: 0.51669\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:07<00:00, 195.13it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 544.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"[031/050] Train Acc: 0.85836 Loss: 0.40342 | Val Acc: 0.85337 loss: 0.51891\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:07<00:00, 195.24it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 526.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"[032/050] Train Acc: 0.85838 Loss: 0.40398 | Val Acc: 0.85378 loss: 0.51729\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:07<00:00, 197.00it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 543.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"[033/050] Train Acc: 0.85843 Loss: 0.40347 | Val Acc: 0.85359 loss: 0.51626\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:07<00:00, 196.81it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 542.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[034/050] Train Acc: 0.85848 Loss: 0.40358 | Val Acc: 0.85298 loss: 0.51567\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:07<00:00, 196.91it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 531.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[035/050] Train Acc: 0.85820 Loss: 0.40278 | Val Acc: 0.85393 loss: 0.51706\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 198.32it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 548.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"[036/050] Train Acc: 0.85834 Loss: 0.40357 | Val Acc: 0.85370 loss: 0.51630\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:07<00:00, 196.38it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 538.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"[037/050] Train Acc: 0.85828 Loss: 0.40401 | Val Acc: 0.85385 loss: 0.51680\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:07<00:00, 197.11it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 544.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"[038/050] Train Acc: 0.85832 Loss: 0.40338 | Val Acc: 0.85359 loss: 0.51573\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 200.47it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 558.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"[039/050] Train Acc: 0.85794 Loss: 0.40386 | Val Acc: 0.85288 loss: 0.51925\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 199.58it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 549.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"[040/050] Train Acc: 0.85810 Loss: 0.40348 | Val Acc: 0.85289 loss: 0.51449\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 199.09it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 536.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"[041/050] Train Acc: 0.85850 Loss: 0.40238 | Val Acc: 0.85341 loss: 0.51749\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 200.53it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 552.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"[042/050] Train Acc: 0.85854 Loss: 0.40332 | Val Acc: 0.85348 loss: 0.51613\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 200.56it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 555.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"[043/050] Train Acc: 0.85824 Loss: 0.40350 | Val Acc: 0.85323 loss: 0.51726\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 199.61it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 548.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"[044/050] Train Acc: 0.85806 Loss: 0.40351 | Val Acc: 0.85363 loss: 0.51581\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 199.10it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 551.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"[045/050] Train Acc: 0.85828 Loss: 0.40322 | Val Acc: 0.85389 loss: 0.51534\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 199.99it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 547.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"[046/050] Train Acc: 0.85825 Loss: 0.40340 | Val Acc: 0.85348 loss: 0.51544\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:07<00:00, 197.03it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 548.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"[047/050] Train Acc: 0.85838 Loss: 0.40343 | Val Acc: 0.85221 loss: 0.52153\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:07<00:00, 196.74it/s]\n100%|██████████| 3282/3282 [00:06<00:00, 540.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"[048/050] Train Acc: 0.85827 Loss: 0.40358 | Val Acc: 0.85328 loss: 0.51737\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 198.89it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 547.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"[049/050] Train Acc: 0.85854 Loss: 0.40399 | Val Acc: 0.85406 loss: 0.51490\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13238/13238 [01:06<00:00, 198.74it/s]\n100%|██████████| 3282/3282 [00:05<00:00, 549.78it/s]","output_type":"stream"},{"name":"stdout","text":"[050/050] Train Acc: 0.85860 Loss: 0.40341 | Val Acc: 0.85328 loss: 0.51899\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"del train_set, val_set\ndel train_loader, val_loader\ngc.collect()","metadata":{"id":"ab33MxosWLmG","outputId":"0d5e2cc6-46f3-41b9-ea09-79fdf660898f","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2025-07-01T15:13:23.098224Z","iopub.execute_input":"2025-07-01T15:13:23.098979Z","iopub.status.idle":"2025-07-01T15:13:23.532149Z","shell.execute_reply.started":"2025-07-01T15:13:23.098944Z","shell.execute_reply":"2025-07-01T15:13:23.531143Z"},"trusted":true},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"23"},"metadata":{}}],"execution_count":77},{"cell_type":"markdown","source":"# Testing\nCreate a testing dataset, and load model from the saved checkpoint.","metadata":{"id":"1Hi7jTn3PX-m"}},{"cell_type":"code","source":"# load data\ntest_X = preprocess_data(split='test', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes)\ntest_set = LibriDataset(test_X, None)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)","metadata":{"id":"VOG1Ou0PGrhc","outputId":"3373d328-bb42-48ec-92f2-e2e935c3344c","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2025-07-01T15:13:25.676041Z","iopub.execute_input":"2025-07-01T15:13:25.676368Z","iopub.status.idle":"2025-07-01T15:13:28.268481Z","shell.execute_reply.started":"2025-07-01T15:13:25.676341Z","shell.execute_reply":"2025-07-01T15:13:28.267604Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[Dataset] - # phone classes: 41, number of utterances for test: 857\n","output_type":"stream"},{"name":"stderr","text":"857it [00:02, 342.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"[INFO] test set\ntorch.Size([527364, 429])\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"# load model\nmodel = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\nmodel.load_state_dict(torch.load(model_path))","metadata":{"id":"ay0Fu8Ovkdad","outputId":"fe130106-a997-4985-fc4b-5102414afe31","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2025-07-01T15:13:29.765602Z","iopub.execute_input":"2025-07-01T15:13:29.766344Z","iopub.status.idle":"2025-07-01T15:13:29.813222Z","shell.execute_reply.started":"2025-07-01T15:13:29.766310Z","shell.execute_reply":"2025-07-01T15:13:29.812001Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3352857437.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1605\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Classifier:\n\tMissing key(s) in state_dict: \"fc.0.block.3.weight\", \"fc.0.block.3.bias\", \"fc.0.block.5.weight\", \"fc.0.block.5.bias\", \"fc.0.block.5.running_mean\", \"fc.0.block.5.running_var\", \"fc.0.block.7.weight\", \"fc.0.block.7.bias\", \"fc.1.block.3.weight\", \"fc.1.block.3.bias\", \"fc.1.block.5.weight\", \"fc.1.block.5.bias\", \"fc.1.block.5.running_mean\", \"fc.1.block.5.running_var\", \"fc.1.block.7.weight\", \"fc.1.block.7.bias\", \"fc.2.block.3.weight\", \"fc.2.block.3.bias\", \"fc.2.block.5.weight\", \"fc.2.block.5.bias\", \"fc.2.block.5.running_mean\", \"fc.2.block.5.running_var\", \"fc.2.block.7.weight\", \"fc.2.block.7.bias\", \"fc.3.block.3.weight\", \"fc.3.block.3.bias\", \"fc.3.block.5.weight\", \"fc.3.block.5.bias\", \"fc.3.block.5.running_mean\", \"fc.3.block.5.running_var\", \"fc.3.block.7.weight\", \"fc.3.block.7.bias\". \n\tUnexpected key(s) in state_dict: \"fc.0.block.0.weight\", \"fc.0.block.0.bias\", \"fc.1.block.0.weight\", \"fc.1.block.0.bias\", \"fc.2.block.0.weight\", \"fc.2.block.0.bias\", \"fc.3.block.0.weight\", \"fc.3.block.0.bias\". \n\tsize mismatch for fc.0.block.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.0.block.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.0.block.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.0.block.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.1.block.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.1.block.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.1.block.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.1.block.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.2.block.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.2.block.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.2.block.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.2.block.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.3.block.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.3.block.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.3.block.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.3.block.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024])."],"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for Classifier:\n\tMissing key(s) in state_dict: \"fc.0.block.3.weight\", \"fc.0.block.3.bias\", \"fc.0.block.5.weight\", \"fc.0.block.5.bias\", \"fc.0.block.5.running_mean\", \"fc.0.block.5.running_var\", \"fc.0.block.7.weight\", \"fc.0.block.7.bias\", \"fc.1.block.3.weight\", \"fc.1.block.3.bias\", \"fc.1.block.5.weight\", \"fc.1.block.5.bias\", \"fc.1.block.5.running_mean\", \"fc.1.block.5.running_var\", \"fc.1.block.7.weight\", \"fc.1.block.7.bias\", \"fc.2.block.3.weight\", \"fc.2.block.3.bias\", \"fc.2.block.5.weight\", \"fc.2.block.5.bias\", \"fc.2.block.5.running_mean\", \"fc.2.block.5.running_var\", \"fc.2.block.7.weight\", \"fc.2.block.7.bias\", \"fc.3.block.3.weight\", \"fc.3.block.3.bias\", \"fc.3.block.5.weight\", \"fc.3.block.5.bias\", \"fc.3.block.5.running_mean\", \"fc.3.block.5.running_var\", \"fc.3.block.7.weight\", \"fc.3.block.7.bias\". \n\tUnexpected key(s) in state_dict: \"fc.0.block.0.weight\", \"fc.0.block.0.bias\", \"fc.1.block.0.weight\", \"fc.1.block.0.bias\", \"fc.2.block.0.weight\", \"fc.2.block.0.bias\", \"fc.3.block.0.weight\", \"fc.3.block.0.bias\". \n\tsize mismatch for fc.0.block.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.0.block.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.0.block.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.0.block.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.1.block.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.1.block.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.1.block.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.1.block.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.2.block.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.2.block.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.2.block.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.2.block.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.3.block.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.3.block.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.3.block.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for fc.3.block.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).","output_type":"error"}],"execution_count":79},{"cell_type":"markdown","source":"Make prediction.","metadata":{"id":"zp-DV1p4r7Nz"}},{"cell_type":"code","source":"pred = np.array([], dtype=np.int32)\n\nmodel.eval()\nwith torch.no_grad():\n    for i, batch in enumerate(tqdm(test_loader)):\n        features = batch\n        features = features.to(device)\n\n        outputs = model(features)\n\n        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n","metadata":{"id":"84HU5GGjPqR0","outputId":"b49ffee0-1785-419d-e56c-0ddd734b2c99","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2025-07-01T15:13:35.403021Z","iopub.execute_input":"2025-07-01T15:13:35.403888Z","iopub.status.idle":"2025-07-01T15:13:35.447103Z","shell.execute_reply.started":"2025-07-01T15:13:35.403856Z","shell.execute_reply":"2025-07-01T15:13:35.445807Z"},"trusted":true},"outputs":[{"name":"stderr","text":"  0%|          | 0/4121 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3548419398.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get the index of the class with the highest probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/2282713224.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/2282713224.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2439\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2440\u001b[0m     )\n\u001b[1;32m   2441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 429 elements not 1024"],"ename":"RuntimeError","evalue":"running_mean should contain 429 elements not 1024","output_type":"error"}],"execution_count":80},{"cell_type":"markdown","source":"Write prediction to a CSV file.\n\nAfter finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle.","metadata":{"id":"wyZqy40Prz0v"}},{"cell_type":"code","source":"with open('prediction.csv', 'w') as f:\n    f.write('Id,Class\\n')\n    for i, y in enumerate(pred):\n        f.write('{},{}\\n'.format(i, y))","metadata":{"id":"GuljYSPHcZir","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2025-07-01T15:13:41.014400Z","iopub.execute_input":"2025-07-01T15:13:41.014977Z","iopub.status.idle":"2025-07-01T15:13:41.020335Z","shell.execute_reply.started":"2025-07-01T15:13:41.014944Z","shell.execute_reply":"2025-07-01T15:13:41.019329Z"},"trusted":true},"outputs":[],"execution_count":82}]}